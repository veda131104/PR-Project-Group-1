{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8795f15a-46c9-4517-afb0-96f72903c96d",
   "metadata": {},
   "source": [
    "### DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bc3ea9-6260-4e8c-b469-8d01e801e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'UD_Chinese-GSDSimp' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/UniversalDependencies/UD_Chinese-GSDSimp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0053bafd-e339-4c93-80a7-b52c8f039c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting hmmlearn\n",
      "  Downloading hmmlearn-0.3.2-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\veda chatiyode\\appdata\\roaming\\python\\python311\\site-packages (from hmmlearn) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in c:\\users\\veda chatiyode\\appdata\\roaming\\python\\python311\\site-packages (from hmmlearn) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\veda chatiyode\\appdata\\roaming\\python\\python311\\site-packages (from hmmlearn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\veda chatiyode\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\veda chatiyode\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.4.0)\n",
      "Downloading hmmlearn-0.3.2-cp311-cp311-win_amd64.whl (125 kB)\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install hmmlearn\n",
    "\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39a10f-dac2-43f9-b776-1b0b28cb81b3",
   "metadata": {},
   "source": [
    "### TRAINING HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0207f5ea-9028-491d-8932-79463a5d9ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8354\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "# Step 1: Load and preprocess the CoNLL formatted data\n",
    "def read_conllu_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentence = []\n",
    "        pos_tags = []\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                if sentence and pos_tags:\n",
    "                    data.append((sentence, pos_tags))\n",
    "                    sentence = []\n",
    "                    pos_tags = []\n",
    "            else:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) > 1:\n",
    "                    sentence.append(parts[1])  # Word\n",
    "                    pos_tags.append(parts[3])   # POS tag\n",
    "    return data\n",
    "\n",
    "# Step 2: HMM Training - Calculate transition and emission probabilities with Laplace Smoothing\n",
    "def train_hmm(data, laplace_smoothing=0.01):\n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "    pos_counts = defaultdict(int)\n",
    "    \n",
    "    for sentence, pos_tags in data:\n",
    "        prev_pos = \"<START>\"\n",
    "        for i in range(len(sentence)):\n",
    "            word, pos = sentence[i], pos_tags[i]\n",
    "            transition_counts[prev_pos][pos] += 1\n",
    "            emission_counts[pos][word] += 1\n",
    "            pos_counts[pos] += 1\n",
    "            prev_pos = pos\n",
    "        # Mark the end of the sentence\n",
    "        transition_counts[prev_pos][\"<END>\"] += 1\n",
    "    \n",
    "    # Calculate transition probabilities with Laplace smoothing\n",
    "    transition_probs = {}\n",
    "    for prev_pos, next_pos_dict in transition_counts.items():\n",
    "        total_count = sum(next_pos_dict.values()) + laplace_smoothing * len(pos_counts)\n",
    "        transition_probs[prev_pos] = {pos: (count + laplace_smoothing) / total_count\n",
    "                                      for pos, count in next_pos_dict.items()}\n",
    "    \n",
    "    # Calculate emission probabilities with Laplace smoothing\n",
    "    emission_probs = {}\n",
    "    for pos, word_dict in emission_counts.items():\n",
    "        total_count = sum(word_dict.values()) + laplace_smoothing * (len(emission_counts[pos]) + 1)  # +1 for unseen words\n",
    "        emission_probs[pos] = {word: (count + laplace_smoothing) / total_count\n",
    "                               for word, count in word_dict.items()}\n",
    "    \n",
    "    return transition_probs, emission_probs, pos_counts\n",
    "\n",
    "# Log version of handle_unknown_word\n",
    "def handle_unknown_word(word, emission_probs, pos_counts, smoothing_factor=1e-6):\n",
    "    if word in emission_probs:\n",
    "        return log(emission_probs[word])\n",
    "    elif word.endswith(\"ing\"):\n",
    "        return log(emission_probs.get(\"VERB\", smoothing_factor))\n",
    "    elif word[0].isupper():\n",
    "        return log(emission_probs.get(\"PROPN\", smoothing_factor))\n",
    "    else:\n",
    "        return log(emission_probs.get(\"NOUN\", smoothing_factor))\n",
    "\n",
    "\n",
    "# Update viterbi algorithm to work with log probabilities\n",
    "def viterbi(sentence, transition_probs, emission_probs, pos_counts):\n",
    "    pos_tags = list(pos_counts.keys())\n",
    "\n",
    "    # Initialize Viterbi matrix and backpointer matrix\n",
    "    viterbi_matrix = np.full((len(pos_tags), len(sentence)), -np.inf)  # log(0) = -inf\n",
    "    backpointer = np.zeros((len(pos_tags), len(sentence)), dtype=int)\n",
    "\n",
    "    # Initialization step\n",
    "    for i, pos in enumerate(pos_tags):\n",
    "        emission_prob = handle_unknown_word(sentence[0], emission_probs[pos], pos_counts)\n",
    "        viterbi_matrix[i, 0] = log(transition_probs[\"<START>\"].get(pos, 1e-6)) + emission_prob\n",
    "\n",
    "    # Recursion step\n",
    "    for t in range(1, len(sentence)):\n",
    "        for i, pos in enumerate(pos_tags):\n",
    "            max_prob = -np.inf\n",
    "            max_state = 0\n",
    "            for j, prev_pos in enumerate(pos_tags):\n",
    "                prob = (viterbi_matrix[j, t-1] + \n",
    "                        log(transition_probs[prev_pos].get(pos, 1e-6)) + \n",
    "                        handle_unknown_word(sentence[t], emission_probs[pos], pos_counts))\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_state = j\n",
    "            viterbi_matrix[i, t] = max_prob\n",
    "            backpointer[i, t] = max_state\n",
    "\n",
    "    # Termination step\n",
    "    best_last_state = np.argmax(viterbi_matrix[:, len(sentence)-1])\n",
    "\n",
    "    # Backtrack to find the best path\n",
    "    best_path = [best_last_state]\n",
    "    for t in range(len(sentence)-1, 0, -1):\n",
    "        best_last_state = backpointer[best_last_state, t]\n",
    "        best_path.insert(0, best_last_state)\n",
    "\n",
    "    # Convert state indices back to POS tags\n",
    "    best_pos_sequence = [pos_tags[state] for state in best_path]\n",
    "    return best_pos_sequence\n",
    "\n",
    "# Step 4: Calculate accuracy\n",
    "def calculate_accuracy(predicted_tags, true_tags):\n",
    "    correct = sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
    "    return correct / len(true_tags) if true_tags else 0.0\n",
    "\n",
    "# Load your dataset\n",
    "train_data_path = \"UD_Chinese-GSDSimp/zh_gsdsimp-ud-train.conllu\"\n",
    "test_data_path = \"UD_Chinese-GSDSimp/zh_gsdsimp-ud-test.conllu\"\n",
    "\n",
    "train_data = read_conllu_data(train_data_path)\n",
    "test_data = read_conllu_data(test_data_path)\n",
    "\n",
    "# Train the HMM model with Laplace smoothing (adjust the value of laplace_smoothing)\n",
    "transition_probs, emission_probs, pos_counts = train_hmm(train_data, laplace_smoothing=0.01)\n",
    "\n",
    "\n",
    "# Test the HMM model and calculate accuracy\n",
    "all_predicted_tags = []\n",
    "all_true_tags = []\n",
    "\n",
    "for sentence, true_pos_tags in test_data:\n",
    "    predicted_tags = viterbi(sentence, transition_probs, emission_probs, pos_counts)\n",
    "    all_predicted_tags.extend(predicted_tags)\n",
    "    all_true_tags.extend(true_pos_tags)\n",
    "\n",
    "accuracy = calculate_accuracy(all_predicted_tags, all_true_tags)\n",
    "\n",
    "# Output accuracy\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd1435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3997\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6104a87-9094-4291-89f1-deb8611ee5aa",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "56226029-77b5-4135-b235-9455caeecda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Feature extraction\n",
    "def extract_features_and_labels(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for sentence, pos_tags in data:\n",
    "        for i, word in enumerate(sentence):\n",
    "            features.append({\n",
    "                'word': word,\n",
    "                'prev_word': sentence[i - 1] if i > 0 else \"<START>\",\n",
    "                'next_word': sentence[i + 1] if i < len(sentence) - 1 else \"<END>\",\n",
    "            })\n",
    "            labels.append(pos_tags[i])\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Extract features and labels from training data\n",
    "train_features, train_labels = extract_features_and_labels(train_data)\n",
    "\n",
    "# Convert features to a sparse matrix suitable for Logistic Regression\n",
    "vectorizer = DictVectorizer(sparse=True)  # Change to sparse=True\n",
    "X_train = vectorizer.fit_transform(train_features)\n",
    "y_train = train_labels\n",
    "\n",
    "# Step 2: Train the Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Test the Logistic Regression model\n",
    "test_features, test_labels = extract_features_and_labels(test_data)\n",
    "X_test = vectorizer.transform(test_features)\n",
    "\n",
    "# Make predictions\n",
    "predicted_tags_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Step 4: Calculate accuracy for Logistic Regression\n",
    "accuracy_lr = accuracy_score(test_labels, predicted_tags_lr)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51d673-af1e-4765-821e-5fbbc9fd5417",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5c090c95-67f3-409f-9090-8f0350ccb1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veda Chatiyode\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Extract features and labels from training data (as defined previously)\n",
    "train_features, train_labels = extract_features_and_labels(train_data)\n",
    "\n",
    "# Convert features to a sparse matrix suitable for SVM\n",
    "vectorizer = DictVectorizer(sparse=True)  # Keep it sparse\n",
    "X_train = vectorizer.fit_transform(train_features)\n",
    "y_train = train_labels\n",
    "\n",
    "# Step 2: Train the Support Vector Machine model\n",
    "svm_model = SVC(kernel='linear', max_iter=1000)  # You can choose different kernels as needed\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Test the SVM model\n",
    "test_features, test_labels = extract_features_and_labels(test_data)\n",
    "X_test = vectorizer.transform(test_features)\n",
    "\n",
    "# Make predictions\n",
    "predicted_tags_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Step 4: Calculate accuracy for SVM\n",
    "accuracy_svm = accuracy_score(test_labels, predicted_tags_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51473e16-fa92-4130-a37d-b24744fe8fbc",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f0a3c797-418f-45a2-9502-a32b1b72ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Extract features and labels from training data (as defined previously)\n",
    "train_features, train_labels = extract_features_and_labels(train_data)\n",
    "\n",
    "# Convert features to a sparse matrix suitable for Random Forest\n",
    "vectorizer = DictVectorizer(sparse=True)  # Keep it sparse\n",
    "X_train = vectorizer.fit_transform(train_features)\n",
    "y_train = train_labels\n",
    "\n",
    "# Step 2: Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust n_estimators as needed\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Test the Random Forest model\n",
    "test_features, test_labels = extract_features_and_labels(test_data)\n",
    "X_test = vectorizer.transform(test_features)\n",
    "\n",
    "# Make predictions\n",
    "predicted_tags_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Step 4: Calculate accuracy for Random Forest\n",
    "accuracy_rf = accuracy_score(test_labels, predicted_tags_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb3610-e812-4677-aa17-184f28ac23c9",
   "metadata": {},
   "source": [
    "### LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "08f759c8-44d8-43db-928e-2297ff26d766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM model with sparse dataset...\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.784922\n",
      "LightGBM Model Accuracy: 0.7366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np  # Import numpy\n",
    "\n",
    "# Step 1: Prepare the feature matrix and target labels using sparse representation\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "X = vectorizer.fit_transform(train_features)  # Keep the matrix sparse\n",
    "\n",
    "# Convert labels to a numpy array to ensure correct format\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(train_labels)  # Encode labels to numeric values\n",
    "\n",
    "# Step 2: Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Prepare LightGBM datasets\n",
    "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)  # Use free_raw_data=False to keep sparse format\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train, free_raw_data=False)\n",
    "\n",
    "# Step 4: Define LightGBM parameters\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',  # Use 'multiclass' for multi-class classification\n",
    "    'metric': 'multi_logloss',  # Use 'multi_logloss' for multi-class\n",
    "    'num_class': len(np.unique(y)),  # Set the number of classes\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Step 5: Train the LightGBM model with early stopping using a callback\n",
    "print(\"Training LightGBM model with sparse dataset...\")\n",
    "model = lgb.train(params,\n",
    "                  lgb_train,\n",
    "                  num_boost_round=100,\n",
    "                  valid_sets=[lgb_eval],\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=10)])\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class for each sample\n",
    "\n",
    "# Step 7: Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "print(f\"LightGBM Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf84d6b-83ed-42d7-9c5a-b143a5e46a1d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ad8b3a3f-d800-4509-9a04-11c596292f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.2483 - loss: 2.3669 - val_accuracy: 0.7478 - val_loss: 1.4590\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.7473 - loss: 1.2857 - val_accuracy: 0.3609 - val_loss: 0.5561\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.3952 - loss: 0.5773 - val_accuracy: 0.3839 - val_loss: 0.3613\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.4290 - loss: 0.3380 - val_accuracy: 0.3899 - val_loss: 0.3081\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4454 - loss: 0.2464 - val_accuracy: 0.3924 - val_loss: 0.2876\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4556 - loss: 0.2051 - val_accuracy: 0.3952 - val_loss: 0.2764\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.4600 - loss: 0.1708 - val_accuracy: 0.3958 - val_loss: 0.2779\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.4573 - loss: 0.1487 - val_accuracy: 0.3962 - val_loss: 0.2776\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4631 - loss: 0.1256 - val_accuracy: 0.3951 - val_loss: 0.2875\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.5194 - loss: 0.1122 - val_accuracy: 0.9160 - val_loss: 0.2916\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9198 - loss: 0.2890\n",
      "Test Accuracy: 0.9160\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "Sentence 1: 然而 ， 这样 的 处理 也 衍生 了 一些 问题 。\n",
      "True Tags: ['SCONJ', 'PUNCT', 'PRON', 'PART', 'NOUN', 'SCONJ', 'VERB', 'AUX', 'ADJ', 'NOUN', 'PUNCT', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB']\n",
      "Predicted Tags: ['SCONJ', 'PUNCT', 'PRON', 'PART', 'NOUN', 'SCONJ', 'VERB', 'AUX', 'ADJ', 'NOUN', 'PUNCT', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB']\n",
      "\n",
      "\n",
      "Sentence 2: 自从 2004 年 提出 了 兴建 人文 大楼 的 构想 ， 企业 界 陆续 有 人 提供 捐款 。\n",
      "True Tags: ['ADP', 'NUM', 'NOUN', 'VERB', 'AUX', 'VERB', 'PROPN', 'NOUN', 'SCONJ', 'NOUN', 'PUNCT', 'NOUN', 'PART', 'ADV', 'VERB', 'NOUN', 'VERB', 'NOUN', 'PUNCT', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB']\n",
      "Predicted Tags: ['ADP', 'NUM', 'NOUN', 'VERB', 'AUX', 'VERB', 'NOUN', 'NOUN', 'PART', 'VERB', 'PUNCT', 'NOUN', 'PART', 'ADV', 'VERB', 'NOUN', 'VERB', 'VERB', 'PUNCT', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB']\n",
      "\n",
      "\n",
      "Sentence 3: 杜鹃花 为 温带 植物 ， 台北 虽然 在 亚 热带 ， 但 冬季 的 东北 季风 却 使得 杜鹃花 在 台大 宜然自得 。\n",
      "True Tags: ['NOUN', 'AUX', 'NOUN', 'NOUN', 'PUNCT', 'PROPN', 'ADP', 'VERB', 'PART', 'NOUN', 'PUNCT', 'SCONJ', 'NOUN', 'PART', 'NOUN', 'NOUN', 'SCONJ', 'VERB', 'NOUN', 'VERB', 'PROPN', 'VERB', 'PUNCT', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB']\n",
      "Predicted Tags: ['VERB', 'AUX', 'NOUN', 'NOUN', 'PUNCT', 'PROPN', 'ADP', 'VERB', 'PROPN', 'NOUN', 'PUNCT', 'SCONJ', 'NOUN', 'PART', 'NOUN', 'NOUN', 'SCONJ', 'VERB', 'VERB', 'ADP', 'PROPN', 'VERB', 'PUNCT', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB', 'VERB']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Feature extraction\n",
    "def extract_sentences_and_labels(data):\n",
    "    sentences = [sentence for sentence, _ in data]\n",
    "    labels = [pos_tags for _, pos_tags in data]\n",
    "    return sentences, labels\n",
    "\n",
    "# Extract sentences and labels from the training and testing data\n",
    "train_sentences, train_labels = extract_sentences_and_labels(train_data)\n",
    "test_sentences, test_labels = extract_sentences_and_labels(test_data)\n",
    "\n",
    "# Step 2: Prepare word and tag dictionaries\n",
    "all_words = [word for sentence in train_sentences for word in sentence]\n",
    "all_tags = [tag for tags in train_labels for tag in tags]\n",
    "\n",
    "# Create a word index and tag index\n",
    "word2idx = {word: idx + 1 for idx, word in enumerate(set(all_words))}  # +1 because 0 is reserved for padding\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(set(all_tags))}\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_LEN = 50\n",
    "EMBEDDING_DIM = 64\n",
    "LSTM_UNITS = 64\n",
    "NUM_CLASSES = len(tag2idx)\n",
    "\n",
    "# Step 3: Convert sentences and labels to sequences of indices\n",
    "def encode_sentences_and_labels(sentences, labels, word2idx, tag2idx, max_len):\n",
    "    X = [[word2idx.get(word, 0) for word in sentence] for sentence in sentences]  \n",
    "    y = [[tag2idx[tag] for tag in tags] for tags in labels]\n",
    "    X_padded = pad_sequences(X, maxlen=max_len, padding='post')\n",
    "    y_padded = pad_sequences(y, maxlen=max_len, padding='post')\n",
    "    return X_padded, y_padded\n",
    "\n",
    "# Encode and pad the training and testing data\n",
    "X_train, y_train = encode_sentences_and_labels(train_sentences, train_labels, word2idx, tag2idx, MAX_LEN)\n",
    "X_test, y_test = encode_sentences_and_labels(test_sentences, test_labels, word2idx, tag2idx, MAX_LEN)\n",
    "\n",
    "# Step 4: Convert labels to categorical values\n",
    "y_train = [to_categorical(i, num_classes=NUM_CLASSES) for i in y_train]\n",
    "y_test = [to_categorical(i, num_classes=NUM_CLASSES) for i in y_test]\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays for LSTM training\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Step 5: Build the LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word2idx) + 1, output_dim=EMBEDDING_DIM, mask_zero=True),  \n",
    "    Bidirectional(LSTM(units=LSTM_UNITS, return_sequences=True, recurrent_dropout=0.1)),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax')  # Output layer for each time step\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "evaluation = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {evaluation[1]:.4f}\")\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "predicted_tags_lstm = model.predict(X_test)\n",
    "predicted_tags_lstm = np.argmax(predicted_tags_lstm, axis=-1)\n",
    "\n",
    "# Step 9: Convert indices back to tag labels\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "predicted_tags = [[idx2tag[idx] for idx in sentence] for sentence in predicted_tags_lstm]\n",
    "true_tags = [[idx2tag[np.argmax(tag)] for tag in sentence] for sentence in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa866a4b-b365-4bf4-8093-bfa6b8c6f7a4",
   "metadata": {},
   "source": [
    "### N GRAM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "18ab46a9-5d1b-49d2-9cf9-520311c51056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence: ['我', '爱', '学习']\n",
      "Predicted POS tags: ['PROPN', 'PART', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Step 1: Preprocess the dataset to extract sentences and POS tags\n",
    "def read_conllu_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentence = []\n",
    "        pos_tags = []\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                if sentence and pos_tags:\n",
    "                    data.append((sentence, pos_tags))\n",
    "                    sentence = []\n",
    "                    pos_tags = []\n",
    "            else:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) > 1:\n",
    "                    sentence.append(parts[1])  # Word\n",
    "                    pos_tags.append(parts[3])   # POS tag\n",
    "    return data\n",
    "\n",
    "# Step 2: Train N-gram POS tagging model (Bigram)\n",
    "def train_ngram_pos_tagger(data, n=2):\n",
    "    ngram_counts = defaultdict(lambda: defaultdict(int))\n",
    "    pos_counts = defaultdict(int)\n",
    "    \n",
    "    for sentence, pos_tags in data:\n",
    "        pos_tags = ['<START>'] * (n-1) + pos_tags + ['<END>']  # Padding for N-grams\n",
    "        for i in range(len(pos_tags) - n + 1):\n",
    "            ngram = tuple(pos_tags[i:i+n-1])\n",
    "            next_pos = pos_tags[i+n-1]\n",
    "            ngram_counts[ngram][next_pos] += 1\n",
    "            pos_counts[next_pos] += 1\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    ngram_probs = {ngram: {pos: count / sum(next_pos_dict.values())\n",
    "                           for pos, count in next_pos_dict.items()}\n",
    "                   for ngram, next_pos_dict in ngram_counts.items()}\n",
    "    \n",
    "    return ngram_probs, pos_counts\n",
    "\n",
    "# Step 3: Predict POS tags using the N-gram model\n",
    "def predict_pos_ngram(sentence, ngram_probs, pos_counts, n=2):\n",
    "    pos_tags = ['<START>'] * (n-1)\n",
    "    for word in sentence:\n",
    "        ngram = tuple(pos_tags[-(n-1):])  # Use last (n-1) POS tags\n",
    "        if ngram in ngram_probs:\n",
    "            predicted_pos = max(ngram_probs[ngram], key=ngram_probs[ngram].get)\n",
    "        else:\n",
    "            predicted_pos = max(pos_counts, key=pos_counts.get)  # Fallback to most common POS\n",
    "        pos_tags.append(predicted_pos)\n",
    "    return pos_tags[n-1:]  # Remove padding\n",
    "\n",
    "# Load your dataset\n",
    "train_data_path = \"UD_Chinese-GSDSimp/zh_gsdsimp-ud-train.conllu\"\n",
    "train_data = read_conllu_data(train_data_path)\n",
    "\n",
    "# Train the N-gram model (bigram here)\n",
    "ngram_probs, pos_counts = train_ngram_pos_tagger(train_data, n=2)\n",
    "\n",
    "# Test N-gram POS Tagging on a sample sentence\n",
    "sample_sentence = [\"我\", \"爱\", \"学习\"]  # Example Chinese sentence\n",
    "predicted_pos_tags = predict_pos_ngram(sample_sentence, ngram_probs, pos_counts, n=2)\n",
    "\n",
    "print(\"Sample sentence:\", sample_sentence)\n",
    "print(\"Predicted POS tags:\", predicted_pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a0b8e-98c9-4522-ab1e-8b1017b1195f",
   "metadata": {},
   "source": [
    "### SENTIMENT POLARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56dcba8c-ffac-4208-89ab-e88cf632e4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SnowNLP\n",
      "  Downloading snownlp-0.12.3.tar.gz (37.6 MB)\n",
      "     ---------------------------------------- 0.0/37.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/37.6 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/37.6 MB 660.6 kB/s eta 0:00:57\n",
      "     --------------------------------------- 0.1/37.6 MB 751.6 kB/s eta 0:00:50\n",
      "     ---------------------------------------- 0.2/37.6 MB 1.2 MB/s eta 0:00:30\n",
      "     ---------------------------------------- 0.3/37.6 MB 1.5 MB/s eta 0:00:26\n",
      "     ---------------------------------------- 0.4/37.6 MB 1.5 MB/s eta 0:00:25\n",
      "     ---------------------------------------- 0.4/37.6 MB 1.5 MB/s eta 0:00:25\n",
      "      --------------------------------------- 0.5/37.6 MB 1.4 MB/s eta 0:00:26\n",
      "      --------------------------------------- 0.5/37.6 MB 1.4 MB/s eta 0:00:26\n",
      "      --------------------------------------- 0.6/37.6 MB 1.3 MB/s eta 0:00:28\n",
      "      --------------------------------------- 0.7/37.6 MB 1.4 MB/s eta 0:00:27\n",
      "      --------------------------------------- 0.7/37.6 MB 1.4 MB/s eta 0:00:27\n",
      "      --------------------------------------- 0.7/37.6 MB 1.3 MB/s eta 0:00:28\n",
      "      --------------------------------------- 0.8/37.6 MB 1.3 MB/s eta 0:00:28\n",
      "      --------------------------------------- 0.9/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 0.9/37.6 MB 1.3 MB/s eta 0:00:28\n",
      "     - -------------------------------------- 1.0/37.6 MB 1.3 MB/s eta 0:00:28\n",
      "     - -------------------------------------- 1.0/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.1/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.1/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.2/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.3/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.3/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.4/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.4/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.5/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.5/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.6/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.6/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.7/37.6 MB 1.3 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.7/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     - -------------------------------------- 1.8/37.6 MB 1.2 MB/s eta 0:00:30\n",
      "     - -------------------------------------- 1.9/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 1.9/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.0/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.0/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.1/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.1/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.2/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.3/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.3/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.4/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.4/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.5/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.5/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.6/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.6/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.7/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.7/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     -- ------------------------------------- 2.8/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 2.8/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 2.9/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 2.9/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.0/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.1/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.1/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.2/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.2/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.2/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.2/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.2/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.2/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.2/37.6 MB 1.2 MB/s eta 0:00:29\n",
      "     --- ------------------------------------ 3.3/37.6 MB 1.1 MB/s eta 0:00:31\n",
      "     --- ------------------------------------ 3.3/37.6 MB 1.1 MB/s eta 0:00:31\n",
      "     --- ------------------------------------ 3.3/37.6 MB 1.1 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 3.3/37.6 MB 1.1 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 3.3/37.6 MB 1.1 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 3.3/37.6 MB 1.1 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 3.3/37.6 MB 1.1 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 3.4/37.6 MB 1.0 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 3.4/37.6 MB 1.0 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 3.4/37.6 MB 1.0 MB/s eta 0:00:34\n",
      "     --- ------------------------------------ 3.4/37.6 MB 1.0 MB/s eta 0:00:34\n",
      "     --- ------------------------------------ 3.5/37.6 MB 1.0 MB/s eta 0:00:34\n",
      "     --- ------------------------------------ 3.5/37.6 MB 1.0 MB/s eta 0:00:34\n",
      "     --- ----------------------------------- 3.5/37.6 MB 988.9 kB/s eta 0:00:35\n",
      "     --- ----------------------------------- 3.5/37.6 MB 984.4 kB/s eta 0:00:35\n",
      "     --- ----------------------------------- 3.5/37.6 MB 973.2 kB/s eta 0:00:36\n",
      "     --- ----------------------------------- 3.5/37.6 MB 973.2 kB/s eta 0:00:36\n",
      "     --- ----------------------------------- 3.6/37.6 MB 961.2 kB/s eta 0:00:36\n",
      "     --- ----------------------------------- 3.6/37.6 MB 961.2 kB/s eta 0:00:36\n",
      "     --- ----------------------------------- 3.6/37.6 MB 961.2 kB/s eta 0:00:36\n",
      "     --- ----------------------------------- 3.6/37.6 MB 961.2 kB/s eta 0:00:36\n",
      "     --- ----------------------------------- 3.6/37.6 MB 919.0 kB/s eta 0:00:37\n",
      "     --- ----------------------------------- 3.6/37.6 MB 919.6 kB/s eta 0:00:37\n",
      "     --- ----------------------------------- 3.6/37.6 MB 919.6 kB/s eta 0:00:37\n",
      "     --- ----------------------------------- 3.6/37.6 MB 919.6 kB/s eta 0:00:37\n",
      "     --- ----------------------------------- 3.7/37.6 MB 893.2 kB/s eta 0:00:39\n",
      "     --- ----------------------------------- 3.7/37.6 MB 893.2 kB/s eta 0:00:39\n",
      "     --- ----------------------------------- 3.7/37.6 MB 888.5 kB/s eta 0:00:39\n",
      "     --- ----------------------------------- 3.7/37.6 MB 888.5 kB/s eta 0:00:39\n",
      "     --- ----------------------------------- 3.7/37.6 MB 871.5 kB/s eta 0:00:39\n",
      "     --- ----------------------------------- 3.7/37.6 MB 871.5 kB/s eta 0:00:39\n",
      "     --- ----------------------------------- 3.7/37.6 MB 854.3 kB/s eta 0:00:40\n",
      "     --- ----------------------------------- 3.7/37.6 MB 854.3 kB/s eta 0:00:40\n",
      "     --- ----------------------------------- 3.7/37.6 MB 854.3 kB/s eta 0:00:40\n",
      "     --- ----------------------------------- 3.8/37.6 MB 845.0 kB/s eta 0:00:41\n",
      "     --- ----------------------------------- 3.8/37.6 MB 845.0 kB/s eta 0:00:41\n",
      "     --- ----------------------------------- 3.8/37.6 MB 845.0 kB/s eta 0:00:41\n",
      "     --- ----------------------------------- 3.8/37.6 MB 823.2 kB/s eta 0:00:42\n",
      "     --- ----------------------------------- 3.9/37.6 MB 821.9 kB/s eta 0:00:42\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 813.3 kB/s eta 0:00:42\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 809.6 kB/s eta 0:00:42\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 809.6 kB/s eta 0:00:42\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 809.6 kB/s eta 0:00:42\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 794.4 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 794.4 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 794.4 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 794.4 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 794.4 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 794.4 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 3.9/37.6 MB 794.4 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 4.0/37.6 MB 760.5 kB/s eta 0:00:45\n",
      "     ---- ---------------------------------- 4.0/37.6 MB 760.1 kB/s eta 0:00:45\n",
      "     ---- ---------------------------------- 4.1/37.6 MB 766.8 kB/s eta 0:00:44\n",
      "     ---- ---------------------------------- 4.2/37.6 MB 775.1 kB/s eta 0:00:44\n",
      "     ---- ---------------------------------- 4.3/37.6 MB 781.6 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 4.3/37.6 MB 783.8 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 4.3/37.6 MB 783.8 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 4.3/37.6 MB 783.8 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 4.3/37.6 MB 783.8 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 4.4/37.6 MB 769.1 kB/s eta 0:00:44\n",
      "     ---- ---------------------------------- 4.4/37.6 MB 768.3 kB/s eta 0:00:44\n",
      "     ---- ---------------------------------- 4.5/37.6 MB 779.8 kB/s eta 0:00:43\n",
      "     ---- ---------------------------------- 4.6/37.6 MB 790.7 kB/s eta 0:00:42\n",
      "     ---- ---------------------------------- 4.7/37.6 MB 798.3 kB/s eta 0:00:42\n",
      "     ---- ---------------------------------- 4.7/37.6 MB 801.5 kB/s eta 0:00:42\n",
      "     ---- ---------------------------------- 4.8/37.6 MB 803.3 kB/s eta 0:00:41\n",
      "     ----- --------------------------------- 4.8/37.6 MB 805.5 kB/s eta 0:00:41\n",
      "     ----- --------------------------------- 4.9/37.6 MB 809.9 kB/s eta 0:00:41\n",
      "     ----- --------------------------------- 4.9/37.6 MB 812.1 kB/s eta 0:00:41\n",
      "     ----- --------------------------------- 5.0/37.6 MB 814.2 kB/s eta 0:00:41\n",
      "     ----- --------------------------------- 5.1/37.6 MB 817.9 kB/s eta 0:00:40\n",
      "     ----- --------------------------------- 5.1/37.6 MB 819.7 kB/s eta 0:00:40\n",
      "     ----- --------------------------------- 5.2/37.6 MB 824.9 kB/s eta 0:00:40\n",
      "     ----- --------------------------------- 5.2/37.6 MB 824.9 kB/s eta 0:00:40\n",
      "     ----- --------------------------------- 5.2/37.6 MB 822.9 kB/s eta 0:00:40\n",
      "     ----- --------------------------------- 5.3/37.6 MB 823.2 kB/s eta 0:00:40\n",
      "     ----- --------------------------------- 5.4/37.6 MB 828.0 kB/s eta 0:00:39\n",
      "     ----- --------------------------------- 5.4/37.6 MB 831.8 kB/s eta 0:00:39\n",
      "     ----- --------------------------------- 5.4/37.6 MB 831.8 kB/s eta 0:00:39\n",
      "     ----- --------------------------------- 5.5/37.6 MB 833.6 kB/s eta 0:00:39\n",
      "     ----- --------------------------------- 5.5/37.6 MB 835.1 kB/s eta 0:00:39\n",
      "     ----- --------------------------------- 5.6/37.6 MB 834.9 kB/s eta 0:00:39\n",
      "     ----- --------------------------------- 5.7/37.6 MB 837.4 kB/s eta 0:00:39\n",
      "     ----- --------------------------------- 5.8/37.6 MB 848.2 kB/s eta 0:00:38\n",
      "     ------ -------------------------------- 5.8/37.6 MB 851.8 kB/s eta 0:00:38\n",
      "     ------ -------------------------------- 5.9/37.6 MB 854.6 kB/s eta 0:00:38\n",
      "     ------ -------------------------------- 5.9/37.6 MB 855.1 kB/s eta 0:00:38\n",
      "     ------ -------------------------------- 6.0/37.6 MB 859.2 kB/s eta 0:00:37\n",
      "     ------ -------------------------------- 6.1/37.6 MB 860.7 kB/s eta 0:00:37\n",
      "     ------ -------------------------------- 6.1/37.6 MB 860.8 kB/s eta 0:00:37\n",
      "     ------ -------------------------------- 6.1/37.6 MB 864.8 kB/s eta 0:00:37\n",
      "     ------ -------------------------------- 6.2/37.6 MB 866.7 kB/s eta 0:00:37\n",
      "     ------ -------------------------------- 6.3/37.6 MB 869.6 kB/s eta 0:00:37\n",
      "     ------ -------------------------------- 6.3/37.6 MB 870.0 kB/s eta 0:00:36\n",
      "     ------ -------------------------------- 6.4/37.6 MB 872.5 kB/s eta 0:00:36\n",
      "     ------ -------------------------------- 6.4/37.6 MB 874.4 kB/s eta 0:00:36\n",
      "     ------ -------------------------------- 6.5/37.6 MB 876.6 kB/s eta 0:00:36\n",
      "     ------ -------------------------------- 6.5/37.6 MB 877.1 kB/s eta 0:00:36\n",
      "     ------ -------------------------------- 6.6/37.6 MB 879.8 kB/s eta 0:00:36\n",
      "     ------ -------------------------------- 6.6/37.6 MB 881.1 kB/s eta 0:00:36\n",
      "     ------ -------------------------------- 6.7/37.6 MB 881.9 kB/s eta 0:00:36\n",
      "     ------ -------------------------------- 6.7/37.6 MB 881.0 kB/s eta 0:00:36\n",
      "     ------- ------------------------------- 6.8/37.6 MB 886.3 kB/s eta 0:00:35\n",
      "     ------- ------------------------------- 6.9/37.6 MB 887.6 kB/s eta 0:00:35\n",
      "     ------- ------------------------------- 6.9/37.6 MB 890.1 kB/s eta 0:00:35\n",
      "     ------- ------------------------------- 7.0/37.6 MB 891.3 kB/s eta 0:00:35\n",
      "     ------- ------------------------------- 7.0/37.6 MB 892.5 kB/s eta 0:00:35\n",
      "     ------- ------------------------------- 7.1/37.6 MB 895.0 kB/s eta 0:00:35\n",
      "     ------- ------------------------------- 7.1/37.6 MB 896.1 kB/s eta 0:00:35\n",
      "     ------- ------------------------------- 7.2/37.6 MB 899.1 kB/s eta 0:00:34\n",
      "     ------- ------------------------------- 7.2/37.6 MB 899.7 kB/s eta 0:00:34\n",
      "     ------- ------------------------------- 7.3/37.6 MB 900.9 kB/s eta 0:00:34\n",
      "     ------- ------------------------------- 7.4/37.6 MB 904.5 kB/s eta 0:00:34\n",
      "     ------- ------------------------------- 7.4/37.6 MB 904.3 kB/s eta 0:00:34\n",
      "     ------- ------------------------------- 7.5/37.6 MB 905.4 kB/s eta 0:00:34\n",
      "     ------- ------------------------------- 7.5/37.6 MB 908.9 kB/s eta 0:00:34\n",
      "     ------- ------------------------------- 7.6/37.6 MB 908.7 kB/s eta 0:00:34\n",
      "     ------- ------------------------------- 7.6/37.6 MB 909.7 kB/s eta 0:00:33\n",
      "     ------- ------------------------------- 7.7/37.6 MB 912.4 kB/s eta 0:00:33\n",
      "     -------- ------------------------------ 7.7/37.6 MB 913.0 kB/s eta 0:00:33\n",
      "     -------- ------------------------------ 7.8/37.6 MB 915.6 kB/s eta 0:00:33\n",
      "     -------- ------------------------------ 7.8/37.6 MB 915.9 kB/s eta 0:00:33\n",
      "     -------- ------------------------------ 7.9/37.6 MB 917.3 kB/s eta 0:00:33\n",
      "     -------- ------------------------------ 7.9/37.6 MB 918.5 kB/s eta 0:00:33\n",
      "     -------- ------------------------------ 8.0/37.6 MB 918.9 kB/s eta 0:00:33\n",
      "     -------- ------------------------------ 8.1/37.6 MB 922.7 kB/s eta 0:00:33\n",
      "     -------- ------------------------------ 8.1/37.6 MB 923.6 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.2/37.6 MB 923.8 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.2/37.6 MB 923.8 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.2/37.6 MB 920.5 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.3/37.6 MB 917.5 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.3/37.6 MB 919.6 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.4/37.6 MB 928.9 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.5/37.6 MB 933.1 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.6/37.6 MB 932.7 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.6/37.6 MB 934.2 kB/s eta 0:00:32\n",
      "     -------- ------------------------------ 8.7/37.6 MB 936.5 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 8.7/37.6 MB 936.9 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 8.8/37.6 MB 937.1 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 8.8/37.6 MB 940.0 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 8.9/37.6 MB 939.7 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 8.9/37.6 MB 942.6 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 9.0/37.6 MB 943.3 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 9.0/37.6 MB 943.5 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 9.1/37.6 MB 943.7 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 9.2/37.6 MB 946.5 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 9.2/37.6 MB 946.2 kB/s eta 0:00:31\n",
      "     --------- ----------------------------- 9.3/37.6 MB 949.0 kB/s eta 0:00:30\n",
      "     --------- ----------------------------- 9.3/37.6 MB 949.7 kB/s eta 0:00:30\n",
      "     --------- ----------------------------- 9.4/37.6 MB 949.3 kB/s eta 0:00:30\n",
      "     --------- ----------------------------- 9.4/37.6 MB 951.5 kB/s eta 0:00:30\n",
      "     --------- ----------------------------- 9.5/37.6 MB 952.7 kB/s eta 0:00:30\n",
      "     --------- ----------------------------- 9.5/37.6 MB 954.3 kB/s eta 0:00:30\n",
      "     --------- ----------------------------- 9.6/37.6 MB 953.0 kB/s eta 0:00:30\n",
      "     ---------- ---------------------------- 9.7/37.6 MB 955.7 kB/s eta 0:00:30\n",
      "     ---------- ---------------------------- 9.7/37.6 MB 956.7 kB/s eta 0:00:30\n",
      "     ---------- ---------------------------- 9.7/37.6 MB 957.4 kB/s eta 0:00:30\n",
      "     ---------- ---------------------------- 9.8/37.6 MB 958.6 kB/s eta 0:00:29\n",
      "     ---------- ---------------------------- 9.9/37.6 MB 959.7 kB/s eta 0:00:29\n",
      "     ---------- ---------------------------- 9.9/37.6 MB 960.2 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.0/37.6 MB 961.3 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.0/37.6 MB 962.4 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.1/37.6 MB 962.6 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.1/37.6 MB 964.5 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.2/37.6 MB 964.7 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.3/37.6 MB 967.1 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.3/37.6 MB 969.9 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.4/37.6 MB 967.1 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.4/37.6 MB 967.1 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.5/37.6 MB 964.2 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.5/37.6 MB 961.4 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.6/37.6 MB 959.9 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.6/37.6 MB 959.9 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.7/37.6 MB 958.6 kB/s eta 0:00:29\n",
      "     ---------- --------------------------- 10.7/37.6 MB 965.7 kB/s eta 0:00:28\n",
      "     ---------- --------------------------- 10.8/37.6 MB 961.4 kB/s eta 0:00:28\n",
      "     ---------- --------------------------- 10.9/37.6 MB 959.9 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 10.9/37.6 MB 960.0 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.0/37.6 MB 958.6 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.0/37.6 MB 962.8 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.1/37.6 MB 959.9 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.1/37.6 MB 960.0 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.2/37.6 MB 960.0 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.2/37.6 MB 958.6 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.3/37.6 MB 958.6 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.3/37.6 MB 960.0 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.4/37.6 MB 958.6 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.4/37.6 MB 958.6 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.5/37.6 MB 959.9 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.6/37.6 MB 958.6 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.6/37.6 MB 958.6 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.7/37.6 MB 958.6 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.7/37.6 MB 957.2 kB/s eta 0:00:28\n",
      "     ----------- -------------------------- 11.8/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ----------- -------------------------- 11.8/37.6 MB 960.0 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 11.9/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 11.9/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.0/37.6 MB 957.1 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.0/37.6 MB 960.0 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.1/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.2/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.2/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.3/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.3/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.4/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.4/37.6 MB 960.0 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.5/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.5/37.6 MB 957.1 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.6/37.6 MB 960.0 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.6/37.6 MB 958.6 kB/s eta 0:00:27\n",
      "     ------------ ------------------------- 12.7/37.6 MB 958.6 kB/s eta 0:00:26\n",
      "     ------------ ------------------------- 12.7/37.6 MB 957.2 kB/s eta 0:00:26\n",
      "     ------------ ------------------------- 12.8/37.6 MB 957.1 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 12.9/37.6 MB 960.0 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 12.9/37.6 MB 958.6 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.0/37.6 MB 959.9 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.0/37.6 MB 960.0 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.1/37.6 MB 958.6 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.1/37.6 MB 958.6 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.2/37.6 MB 958.6 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.2/37.6 MB 957.1 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.3/37.6 MB 960.0 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.4/37.6 MB 958.6 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.4/37.6 MB 964.2 kB/s eta 0:00:26\n",
      "     ------------- ------------------------ 13.5/37.6 MB 983.1 kB/s eta 0:00:25\n",
      "     ------------- ------------------------ 13.5/37.6 MB 980.0 kB/s eta 0:00:25\n",
      "     -------------- ------------------------- 13.6/37.6 MB 1.0 MB/s eta 0:00:24\n",
      "     -------------- ------------------------- 13.6/37.6 MB 1.0 MB/s eta 0:00:24\n",
      "     -------------- ------------------------- 13.7/37.6 MB 1.0 MB/s eta 0:00:24\n",
      "     -------------- ------------------------- 13.7/37.6 MB 1.0 MB/s eta 0:00:24\n",
      "     -------------- ------------------------- 13.7/37.6 MB 1.0 MB/s eta 0:00:24\n",
      "     -------------- ------------------------- 13.8/37.6 MB 1.0 MB/s eta 0:00:24\n",
      "     -------------- ------------------------- 13.9/37.6 MB 1.0 MB/s eta 0:00:23\n",
      "     -------------- ------------------------- 14.0/37.6 MB 1.1 MB/s eta 0:00:22\n",
      "     -------------- ------------------------- 14.0/37.6 MB 1.1 MB/s eta 0:00:22\n",
      "     -------------- ------------------------- 14.0/37.6 MB 1.1 MB/s eta 0:00:22\n",
      "     -------------- ------------------------- 14.0/37.6 MB 1.1 MB/s eta 0:00:22\n",
      "     --------------- ------------------------ 14.1/37.6 MB 1.1 MB/s eta 0:00:21\n",
      "     --------------- ------------------------ 14.1/37.6 MB 1.1 MB/s eta 0:00:21\n",
      "     --------------- ------------------------ 14.2/37.6 MB 1.2 MB/s eta 0:00:21\n",
      "     --------------- ------------------------ 14.2/37.6 MB 1.2 MB/s eta 0:00:21\n",
      "     --------------- ------------------------ 14.3/37.6 MB 1.2 MB/s eta 0:00:21\n",
      "     --------------- ------------------------ 14.4/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.5/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.6/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.6/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.7/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.7/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.8/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.8/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.9/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 14.9/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 15.0/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 15.0/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     ---------------- ----------------------- 15.1/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     ---------------- ----------------------- 15.2/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     ---------------- ----------------------- 15.2/37.6 MB 1.2 MB/s eta 0:00:20\n",
      "     ---------------- ----------------------- 15.3/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.3/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.4/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.4/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.5/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.5/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.6/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.6/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.7/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.8/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.8/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.9/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 15.9/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.0/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.0/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.1/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.1/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.2/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.3/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.3/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.4/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.4/37.6 MB 1.2 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 16.5/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 16.5/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 16.6/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 16.6/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 16.7/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 16.7/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 16.8/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 16.8/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 16.9/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.0/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.0/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.1/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.1/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.2/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.2/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.3/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.3/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.4/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.4/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.5/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.6/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.6/37.6 MB 1.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 17.7/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 17.7/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 17.8/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 17.8/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 17.8/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 17.9/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.0/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.1/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.1/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.2/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.2/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.3/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.3/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.4/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.4/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.5/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.5/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.6/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.6/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.7/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.8/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 18.8/37.6 MB 1.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 18.9/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 18.9/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.0/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.0/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.1/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.1/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.2/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.3/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.3/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.4/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.4/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.5/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.5/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.6/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.6/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.7/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 19.7/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 19.8/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 19.8/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 19.9/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 19.9/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 20.0/37.6 MB 1.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 20.0/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.1/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.2/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.2/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.3/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.3/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.4/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.4/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.5/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.6/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.6/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 20.7/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 20.7/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 20.8/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 20.8/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 20.8/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 20.9/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 21.0/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 21.0/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 21.1/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 21.1/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 21.2/37.6 MB 1.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 21.2/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 21.3/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 21.4/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 21.4/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 21.5/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 21.5/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 21.6/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.6/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.7/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.7/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.8/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.8/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.8/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.8/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.8/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 21.9/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.0/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.1/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.1/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.1/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.2/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.3/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.3/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.4/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.4/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.5/37.6 MB 1.2 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 22.6/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 22.6/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 22.7/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 22.7/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 22.8/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 22.8/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 22.9/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 22.9/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.0/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.0/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.1/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.1/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.2/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.3/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.3/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.4/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.4/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 23.5/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 23.5/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 23.6/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 23.7/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 23.7/37.6 MB 1.2 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 23.8/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 23.8/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 23.9/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 23.9/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.0/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.0/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.1/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.1/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.2/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.2/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.3/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.4/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 24.4/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 24.5/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 24.5/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 24.6/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 24.6/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 24.7/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 24.8/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 24.8/37.6 MB 1.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 24.9/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 24.9/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 25.0/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 25.0/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 25.1/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 25.1/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 25.2/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 25.2/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 25.3/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 25.3/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.4/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.5/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.5/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.6/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.6/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.7/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.7/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.8/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.8/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.8/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.8/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.8/37.6 MB 1.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.9/37.6 MB 1.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 25.9/37.6 MB 1.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 26.0/37.6 MB 1.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 26.1/37.6 MB 1.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 26.2/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 26.2/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 26.3/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.3/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.4/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.5/37.6 MB 1.2 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.5/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.6/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.6/37.6 MB 1.2 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.7/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.7/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.7/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.8/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.9/37.6 MB 1.2 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 26.9/37.6 MB 1.2 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 27.0/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 27.0/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 27.1/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 27.1/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 27.2/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 27.3/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 27.3/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 27.3/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ----------------------------- ---------- 27.3/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ----------------------------- ---------- 27.3/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ----------------------------- ---------- 27.4/37.6 MB 1.1 MB/s eta 0:00:10\n",
      "     ----------------------------- ---------- 27.5/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 27.5/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 27.6/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 27.7/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 27.7/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 27.8/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 27.8/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 27.9/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 27.9/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 28.0/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 28.1/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 28.1/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 28.2/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 28.2/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 28.3/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 28.3/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 28.3/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 28.4/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 28.4/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 28.5/37.6 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 28.6/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 28.7/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 28.7/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 28.8/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 28.8/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 28.9/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 28.9/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 29.0/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 29.0/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 29.1/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.2/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.2/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.3/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.3/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.4/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.6/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.6/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.7/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.8/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.8/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 29.9/37.6 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 30.0/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 30.0/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 30.0/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 30.0/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 30.0/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.1/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.2/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.2/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.3/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.4/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.4/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.5/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.5/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.6/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.6/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.7/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.8/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.8/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.9/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 30.9/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 31.0/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 31.0/37.6 MB 1.1 MB/s eta 0:00:07\n",
      "     --------------------------------- ------ 31.1/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.1/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.2/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.2/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.3/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.4/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.4/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.5/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.5/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.6/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.6/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.7/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.7/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.8/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.8/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 31.9/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 32.0/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 32.0/37.6 MB 1.1 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 32.1/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.1/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.2/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.2/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.3/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.3/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.4/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.4/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.5/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.6/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.6/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.6/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.7/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.8/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.8/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.9/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 32.9/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 32.9/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 33.0/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 33.1/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 33.2/37.6 MB 1.1 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 33.2/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.2/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.3/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.4/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.4/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.5/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.5/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.6/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.7/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.7/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.8/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 33.8/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 33.9/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 33.9/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 34.0/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 34.0/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 34.1/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 34.2/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 34.2/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 34.3/37.6 MB 1.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 34.3/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 34.4/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 34.4/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 34.5/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 34.5/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 34.6/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 34.6/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 34.7/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 34.7/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 34.8/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 34.9/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 34.9/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.0/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.0/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.1/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.1/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.2/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.2/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.3/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.3/37.6 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 35.4/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 35.5/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 35.5/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 35.6/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 35.6/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 35.7/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 35.7/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 35.8/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 35.8/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 35.9/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 35.9/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 35.9/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.0/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.1/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.1/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.1/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.1/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.1/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.2/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.2/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.3/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.3/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.3/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.4/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.4/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.5/37.6 MB 1.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 36.5/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 36.5/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 36.6/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 36.6/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 36.7/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.7/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.7/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.7/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.7/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.7/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.7/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.8/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.8/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.8/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.9/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.9/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  36.9/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.0/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.0/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.1/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.1/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.2/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.3/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.3/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.3/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.4/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.4/37.6 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.5/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.6/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  37.6/37.6 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 37.6/37.6 MB 1.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: SnowNLP\n",
      "  Building wheel for SnowNLP (setup.py): started\n",
      "  Building wheel for SnowNLP (setup.py): finished with status 'done'\n",
      "  Created wheel for SnowNLP: filename=snownlp-0.12.3-py3-none-any.whl size=37760953 sha256=3de2fa7ee666455f96908796c05d5c83a556efd95d32ec73ee3e98124164f06c\n",
      "  Stored in directory: c:\\users\\veda chatiyode\\appdata\\local\\pip\\cache\\wheels\\8a\\0a\\37\\f15b8568f5463f1427466f701e9d3ba514035eb703f885efee\n",
      "Successfully built SnowNLP\n",
      "Installing collected packages: SnowNLP\n",
      "Successfully installed SnowNLP-0.12.3\n"
     ]
    }
   ],
   "source": [
    "!pip install SnowNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "549d3245-d53c-4903-b6d9-4a446c3ee77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 看似 简单 ， 只 是 二 选 一 做 决择 ， 但 其实 他们 代表 的 是 你 周遭 的 亲朋 好友 ， 试 着 给 你 不同 的 意见 ， 但 追根究底 ， 最后 决定 的 还是 自己 。\n",
      "Sentiment polarity: 0.9988\n",
      "\n",
      "Sentence: 其 便当 都是 买来 的 ， 就算 加热 也是 由 妈妈 负责 （ 后来 揭晓 其实 是 避免 带来 厄运 ） ， 父亲 则 在 电视 台 上班 。\n",
      "Sentiment polarity: 0.9112\n",
      "\n",
      "Sentence: 这 次 游行 最大 的 特色 ， 在 于 越来越 多 年轻 人 上街 游行 ， 而且 当中 不乏 行动 激烈 的 躁 少年 。\n",
      "Sentiment polarity: 0.9954\n",
      "\n",
      "Sentence: 怀孕 期 为 421 至 457 日 。\n",
      "Sentiment polarity: 0.7628\n",
      "\n",
      "Sentence: 婷婷 向 昏迷 中 的 婆婆 诉说 ， 为 什么 生活 会 与 她 想像 的 不 一样 。\n",
      "Sentiment polarity: 0.9977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snownlp import SnowNLP\n",
    "\n",
    "# Step 2: Perform sentiment polarity analysis using SnowNLP\n",
    "def analyze_sentiment_snownlp(sentences):\n",
    "    for sentence in sentences:\n",
    "        s = SnowNLP(sentence)\n",
    "        sentiment_polarity = s.sentiments  # Sentiment score ranges from 0 (negative) to 1 (positive)\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "        print(f\"Sentiment polarity: {sentiment_polarity:.4f}\\n\")\n",
    "\n",
    "# Analyze sentiment using SnowNLP\n",
    "analyze_sentiment_snownlp(sentences[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d3cce-c9ee-4d2f-b95c-a7c772061359",
   "metadata": {},
   "source": [
    "### OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ecb1d66-0718-4878-a717-dda624e99b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best tag sequence: ['PRON', 'AUX', 'ADV']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class HMMTagger:\n",
    "    def __init__(self, training_data):\n",
    "        self.training_data = training_data\n",
    "        self.vocab = set()  # Vocabulary from training\n",
    "        self.tag_count = defaultdict(int)  # Count of each POS tag\n",
    "        self.word_tag_count = defaultdict(lambda: defaultdict(int))  # Count of word given a tag\n",
    "        self.tag_transition_count = defaultdict(lambda: defaultdict(int))  # Count of tag transitions\n",
    "        self.smoothing_value = 1e-6  # Small smoothing value for OOV handling\n",
    "\n",
    "    def train(self):\n",
    "        prev_tag = \"<START>\"\n",
    "        for sentence in self.training_data:\n",
    "            for word, tag in sentence:\n",
    "                self.vocab.add(word)\n",
    "                self.tag_count[tag] += 1\n",
    "                self.word_tag_count[tag][word] += 1\n",
    "                self.tag_transition_count[prev_tag][tag] += 1\n",
    "                prev_tag = tag\n",
    "            self.tag_transition_count[prev_tag][\"<END>\"] += 1\n",
    "\n",
    "    def emission_probability(self, word, tag):\n",
    "        \"\"\"\n",
    "        Calculates the emission probability P(word|tag).\n",
    "        For OOV words, assign a small smoothing probability.\n",
    "        \"\"\"\n",
    "        if word in self.vocab:\n",
    "            return (self.word_tag_count[tag][word] + self.smoothing_value) / (self.tag_count[tag] + self.smoothing_value)\n",
    "        else:\n",
    "            # Handle OOV: Assign small probability\n",
    "            return self.smoothing_value / (self.tag_count[tag] + self.smoothing_value)\n",
    "\n",
    "    def transition_probability(self, prev_tag, current_tag):\n",
    "        \"\"\"\n",
    "        Calculates the transition probability P(tag|prev_tag).\n",
    "        \"\"\"\n",
    "        return (self.tag_transition_count[prev_tag][current_tag] + self.smoothing_value) / \\\n",
    "               (sum(self.tag_transition_count[prev_tag].values()) + self.smoothing_value)\n",
    "\n",
    "    def viterbi(self, sentence):\n",
    "        \"\"\"\n",
    "        Viterbi algorithm to find the most likely sequence of tags for a sentence.\n",
    "        \"\"\"\n",
    "        V = [{}]\n",
    "        path = {}\n",
    "\n",
    "        # Initialize base cases (start probabilities)\n",
    "        for tag in self.tag_count:\n",
    "            V[0][tag] = self.transition_probability(\"<START>\", tag) * self.emission_probability(sentence[0], tag)\n",
    "            path[tag] = [tag]\n",
    "\n",
    "        # Run Viterbi for each word in the sentence\n",
    "        for t in range(1, len(sentence)):\n",
    "            V.append({})\n",
    "            newpath = {}\n",
    "\n",
    "            for tag in self.tag_count:\n",
    "                # For each tag, find the highest probability from previous tags\n",
    "                (prob, best_prev_tag) = max(\n",
    "                    (V[t - 1][prev_tag] * self.transition_probability(prev_tag, tag) *\n",
    "                     self.emission_probability(sentence[t], tag), prev_tag)\n",
    "                    for prev_tag in self.tag_count\n",
    "                )\n",
    "\n",
    "                V[t][tag] = prob\n",
    "                newpath[tag] = path[best_prev_tag] + [tag]\n",
    "\n",
    "            # Update path\n",
    "            path = newpath\n",
    "\n",
    "        # Termination: Find the best final tag sequence\n",
    "        (prob, best_tag) = max((V[len(sentence) - 1][tag], tag) for tag in self.tag_count)\n",
    "\n",
    "        return (prob, path[best_tag])\n",
    "\n",
    "# Sample training data: list of sentences where each sentence is a list of (word, tag) pairs\n",
    "training_data = [\n",
    "    [('I', 'PRON'), ('am', 'AUX'), ('happy', 'ADJ')],\n",
    "    [('She', 'PRON'), ('is', 'AUX'), ('here', 'ADV')],\n",
    "    # Add more training data\n",
    "]\n",
    "\n",
    "# Initialize the tagger and train\n",
    "hmm_tagger = HMMTagger(training_data)\n",
    "hmm_tagger.train()\n",
    "\n",
    "# Sample test sentence with an OOV word\n",
    "test_sentence = ['他', '感到', '高兴']  # 'He feels happy'\n",
    "\n",
    "# Run Viterbi decoding\n",
    "prob, best_tag_sequence = hmm_tagger.viterbi(test_sentence)\n",
    "print(f\"Best tag sequence: {best_tag_sequence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92089eba-4cbf-4791-8bdc-9099b78477a8",
   "metadata": {},
   "source": [
    "### NER - NAMED ENTITY RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd8f70-62cd-405a-b579-b1f642635303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and preprocess the CoNLL formatted data for NER\n",
    "def read_conllu_data_ner(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentence = []\n",
    "        ner_tags = []\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                if sentence and ner_tags:\n",
    "                    data.append((sentence, ner_tags))\n",
    "                    sentence = []\n",
    "                    ner_tags = []\n",
    "            else:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) > 1:\n",
    "                    sentence.append(parts[1])  # Word\n",
    "                    ner_tags.append(parts[5])  # NER tag\n",
    "    return data\n",
    "\n",
    "# Step 2: HMM Training - Calculate transition and emission probabilities for NER\n",
    "def train_hmm_ner(data):\n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "    ner_counts = defaultdict(int)\n",
    "    \n",
    "    for sentence, ner_tags in data:\n",
    "        prev_ner = \"<START>\"\n",
    "        for i in range(len(sentence)):\n",
    "            word, ner = sentence[i], ner_tags[i]\n",
    "            transition_counts[prev_ner][ner] += 1\n",
    "            emission_counts[ner][word] += 1\n",
    "            ner_counts[ner] += 1\n",
    "            prev_ner = ner\n",
    "        # Mark the end of the sentence\n",
    "        transition_counts[prev_ner][\"<END>\"] += 1\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    transition_probs = {prev_ner: {ner: count / sum(next_ner_dict.values())\n",
    "                                   for ner, count in next_ner_dict.items()}\n",
    "                        for prev_ner, next_ner_dict in transition_counts.items()}\n",
    "    \n",
    "    emission_probs = {ner: {word: count / sum(word_dict.values())\n",
    "                            for word, count in word_dict.items()}\n",
    "                      for ner, word_dict in emission_counts.items()}\n",
    "    \n",
    "    return transition_probs, emission_probs, ner_counts\n",
    "\n",
    "# Step 3: Viterbi Algorithm for NER tagging\n",
    "def viterbi_ner(sentence, transition_probs, emission_probs, ner_counts):\n",
    "    ner_tags = list(ner_counts.keys())\n",
    "    \n",
    "    # Initialize Viterbi matrix and backpointer matrix\n",
    "    viterbi_matrix = np.zeros((len(ner_tags), len(sentence)))\n",
    "    backpointer = np.zeros((len(ner_tags), len(sentence)), dtype=int)\n",
    "    \n",
    "    # Initialization step\n",
    "    for i, ner in enumerate(ner_tags):\n",
    "        emission_prob = emission_probs[ner].get(sentence[0], 1e-6)  # Smoothing for unseen words\n",
    "        viterbi_matrix[i, 0] = transition_probs[\"<START>\"].get(ner, 1e-6) * emission_prob\n",
    "    \n",
    "    # Recursion step\n",
    "    for t in range(1, len(sentence)):\n",
    "        for i, ner in enumerate(ner_tags):\n",
    "            max_prob = -1\n",
    "            max_state = 0\n",
    "            for j, prev_ner in enumerate(ner_tags):\n",
    "                prob = (viterbi_matrix[j, t-1] * \n",
    "                        transition_probs[prev_ner].get(ner, 1e-6) * \n",
    "                        emission_probs[ner].get(sentence[t], 1e-6))\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_state = j\n",
    "            viterbi_matrix[i, t] = max_prob\n",
    "            backpointer[i, t] = max_state\n",
    "    \n",
    "    # Termination step\n",
    "    best_last_state = np.argmax(viterbi_matrix[:, len(sentence)-1])\n",
    "    \n",
    "    # Backtrack to find the best path\n",
    "    best_path = [best_last_state]\n",
    "    for t in range(len(sentence)-1, 0, -1):\n",
    "        best_last_state = backpointer[best_last_state, t]\n",
    "        best_path.insert(0, best_last_state)\n",
    "    \n",
    "    # Convert state indices back to NER tags\n",
    "    best_ner_sequence = [ner_tags[state] for state in best_path]\n",
    "    return best_ner_sequence\n",
    "\n",
    "# Step 4: Calculate accuracy\n",
    "def calculate_accuracy_ner(predicted_tags, true_tags):\n",
    "    correct = sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
    "    return correct / len(true_tags) if true_tags else 0.0\n",
    "\n",
    "# Load your dataset (you will need a NER dataset similar to CoNLL 2003)\n",
    "train_data_path = \"UD_Chinese-GSDSimp/zh_gsdsimp-ud-train.conllu\"\n",
    "test_data_path = \"UD_Chinese-GSDSimp/zh_gsdsimp-ud-test.conllu\"\n",
    "\n",
    "train_data = read_conllu_data_ner(train_data_path)\n",
    "test_data = read_conllu_data_ner(test_data_path)\n",
    "\n",
    "# Train the HMM model for NER\n",
    "transition_probs, emission_probs, ner_counts = train_hmm_ner(train_data)\n",
    "\n",
    "# Test the HMM model for NER and calculate accuracy\n",
    "all_predicted_tags = []\n",
    "all_true_tags = []\n",
    "\n",
    "for sentence, true_ner_tags in test_data:\n",
    "    predicted_tags = viterbi_ner(sentence, transition_probs, emission_probs, ner_counts)\n",
    "    all_predicted_tags.extend(predicted_tags)\n",
    "    all_true_tags.extend(true_ner_tags)\n",
    "\n",
    "accuracy = calculate_accuracy_ner(all_predicted_tags, all_true_tags)\n",
    "\n",
    "# Output accuracy\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f8f01e-39fc-4ee9-971d-cf99a7c3eb94",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_your_train_data.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 101\u001b[0m\n\u001b[0;32m     98\u001b[0m train_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_train_data.conllu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m test_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_test_data.conllu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 101\u001b[0m train_data \u001b[38;5;241m=\u001b[39m read_conllu_data_ner(train_data_path)\n\u001b[0;32m    102\u001b[0m test_data \u001b[38;5;241m=\u001b[39m read_conllu_data_ner(test_data_path)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Train the HMM model for NER\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[32], line 7\u001b[0m, in \u001b[0;36mread_conllu_data_ner\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_conllu_data_ner\u001b[39m(file_path):\n\u001b[0;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m         sentence \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m         ner_tags \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_train_data.conllu'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load and preprocess the CoNLL formatted data for NER (Name, Place, Animal, Thing)\n",
    "def read_conllu_data_ner(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentence = []\n",
    "        ner_tags = []\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                if sentence and ner_tags:\n",
    "                    data.append((sentence, ner_tags))\n",
    "                    sentence = []\n",
    "                    ner_tags = []\n",
    "            else:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) > 1:\n",
    "                    sentence.append(parts[1])  # Word\n",
    "                    ner_tags.append(parts[5])  # NER tag (should include B-NAME, B-PLACE, etc.)\n",
    "    return data\n",
    "\n",
    "# Step 2: HMM Training - Calculate transition and emission probabilities for NER\n",
    "def train_hmm_ner(data):\n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "    ner_counts = defaultdict(int)\n",
    "    \n",
    "    for sentence, ner_tags in data:\n",
    "        prev_ner = \"<START>\"\n",
    "        for i in range(len(sentence)):\n",
    "            word, ner = sentence[i], ner_tags[i]\n",
    "            transition_counts[prev_ner][ner] += 1\n",
    "            emission_counts[ner][word] += 1\n",
    "            ner_counts[ner] += 1\n",
    "            prev_ner = ner\n",
    "        # Mark the end of the sentence\n",
    "        transition_counts[prev_ner][\"<END>\"] += 1\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    transition_probs = {prev_ner: {ner: count / sum(next_ner_dict.values())\n",
    "                                   for ner, count in next_ner_dict.items()}\n",
    "                        for prev_ner, next_ner_dict in transition_counts.items()}\n",
    "    \n",
    "    emission_probs = {ner: {word: count / sum(word_dict.values())\n",
    "                            for word, count in word_dict.items()}\n",
    "                      for ner, word_dict in emission_counts.items()}\n",
    "    \n",
    "    return transition_probs, emission_probs, ner_counts\n",
    "\n",
    "# Step 3: Viterbi Algorithm for NER tagging (Name, Place, Animal, Thing)\n",
    "def viterbi_ner(sentence, transition_probs, emission_probs, ner_counts):\n",
    "    ner_tags = list(ner_counts.keys())\n",
    "    \n",
    "    # Initialize Viterbi matrix and backpointer matrix\n",
    "    viterbi_matrix = np.zeros((len(ner_tags), len(sentence)))\n",
    "    backpointer = np.zeros((len(ner_tags), len(sentence)), dtype=int)\n",
    "    \n",
    "    # Initialization step\n",
    "    for i, ner in enumerate(ner_tags):\n",
    "        emission_prob = emission_probs[ner].get(sentence[0], 1e-6)  # Smoothing for unseen words\n",
    "        viterbi_matrix[i, 0] = transition_probs[\"<START>\"].get(ner, 1e-6) * emission_prob\n",
    "    \n",
    "    # Recursion step\n",
    "    for t in range(1, len(sentence)):\n",
    "        for i, ner in enumerate(ner_tags):\n",
    "            max_prob = -1\n",
    "            max_state = 0\n",
    "            for j, prev_ner in enumerate(ner_tags):\n",
    "                prob = (viterbi_matrix[j, t-1] * \n",
    "                        transition_probs[prev_ner].get(ner, 1e-6) * \n",
    "                        emission_probs[ner].get(sentence[t], 1e-6))\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_state = j\n",
    "            viterbi_matrix[i, t] = max_prob\n",
    "            backpointer[i, t] = max_state\n",
    "    \n",
    "    # Termination step\n",
    "    best_last_state = np.argmax(viterbi_matrix[:, len(sentence)-1])\n",
    "    \n",
    "    # Backtrack to find the best path\n",
    "    best_path = [best_last_state]\n",
    "    for t in range(len(sentence)-1, 0, -1):\n",
    "        best_last_state = backpointer[best_last_state, t]\n",
    "        best_path.insert(0, best_last_state)\n",
    "    \n",
    "    # Convert state indices back to NER tags\n",
    "    best_ner_sequence = [ner_tags[state] for state in best_path]\n",
    "    return best_ner_sequence\n",
    "\n",
    "# Step 4: Calculate accuracy\n",
    "def calculate_accuracy_ner(predicted_tags, true_tags):\n",
    "    correct = sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
    "    return correct / len(true_tags) if true_tags else 0.0\n",
    "\n",
    "# Load your dataset (you will need a NER dataset with Name, Place, Animal, Thing tags)\n",
    "\n",
    "train_data = read_conllu_data_ner(train_data_path)\n",
    "test_data = read_conllu_data_ner(test_data_path)\n",
    "\n",
    "# Train the HMM model for NER\n",
    "transition_probs, emission_probs, ner_counts = train_hmm_ner(train_data)\n",
    "\n",
    "# Test the HMM model for NER and calculate accuracy\n",
    "all_predicted_tags = []\n",
    "all_true_tags = []\n",
    "\n",
    "for sentence, true_ner_tags in test_data:\n",
    "    predicted_tags = viterbi_ner(sentence, transition_probs, emission_probs, ner_counts)\n",
    "    \n",
    "    # Print the sentence along with the predicted and true NER tags\n",
    "    print(\"\\nSentence:\", \" \".join(sentence))\n",
    "    for word, pred_tag, true_tag in zip(sentence, predicted_tags, true_ner_tags):\n",
    "        print(f\"Word: {word}, Predicted NER: {pred_tag}, True NER: {true_tag}\")\n",
    "    \n",
    "    all_predicted_tags.extend(predicted_tags)\n",
    "    all_true_tags.extend(true_ner_tags)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = calculate_accuracy_ner(all_predicted_tags, all_true_tags)\n",
    "\n",
    "# Output accuracy\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
